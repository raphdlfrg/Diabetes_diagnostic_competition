{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:13:56.048331Z",
     "start_time": "2024-12-07T00:13:56.018192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading required libraries and fixing the seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "SEED = 1\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Loading dataset & preprocessing the data\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "labels_data = pd.read_csv('data/labels.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Removing useless features\n",
    "X_train = train_data.drop(columns=['Unnamed: 0', 'Age_Group'])\n",
    "y_train = labels_data['Diabetes_binary']\n",
    "X_test = test_data.drop(columns=['Unnamed: 0', 'Age_Group'])\n",
    "\n",
    "# Encoding non-numerical features\n",
    "def feature_encoding(X):\n",
    "    non_numerical_columns_names = X.select_dtypes(exclude=['number']).columns\n",
    "    for column in non_numerical_columns_names:\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "    return X\n",
    "\n",
    "X_train = feature_encoding(X_train)\n",
    "X_test = feature_encoding(X_test)\n",
    "\n",
    "\n",
    "# Normalizing features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:13:57.375742Z",
     "start_time": "2024-12-07T00:13:56.027092Z"
    }
   },
   "id": "76d528b8c1fb1d7f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Implementing functions used for the GridSearch\n",
    "\n",
    "def custom_f1_threshold(estimator, X, y, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compute the F1-score with non-default threshold values\n",
    "    \"\"\"\n",
    "    probs = estimator.predict_proba(X)[:, 1]\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    return f1_score(y, preds)\n",
    "\n",
    "\n",
    "def find_best_params_for_thresholds(model, X_train, y_train, params, thresholds):\n",
    "    \"\"\"\n",
    "    Perform GridSearch with non-default threshold values\n",
    "    \"\"\"\n",
    "    # Implementing Cross validation\n",
    "    strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        print(\"\\nThreshold:\", threshold)\n",
    "        # grid_search = GridSearchCV(model, param_grid=params, scoring=lambda est, X, y: custom_f1_threshold(est, X, y, threshold), cv=strat_kfold)\n",
    "        grid_search = GridSearchCV(model, param_grid=params, scoring=lambda est, X, y: custom_f1_threshold(est, X, y, threshold), cv=strat_kfold)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "\n",
    "        print(\"Best parameters:\", best_params)\n",
    "        print(\"Best F1-Score:\", best_score)\n",
    "\n",
    "        results.append({'threshold': threshold, 'best_params': best_params, 'best_score': best_score})\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:13:57.385114Z",
     "start_time": "2024-12-07T00:13:57.374778Z"
    }
   },
   "id": "ff11bfe25294461f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold: 0.595\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m LogisticRegression(random_state\u001B[38;5;241m=\u001B[39mSEED)\n\u001B[1;32m     11\u001B[0m threshold \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m0.595\u001B[39m, \u001B[38;5;241m0.61\u001B[39m, \u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m---> 12\u001B[0m results \u001B[38;5;241m=\u001B[39m find_best_params_for_thresholds(\u001B[38;5;28mcls\u001B[39m, X_train, y_train, param_grid, threshold)\n",
      "Cell \u001B[0;32mIn[12], line 25\u001B[0m, in \u001B[0;36mfind_best_params_for_thresholds\u001B[0;34m(model, X_train, y_train, params, thresholds)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# grid_search = GridSearchCV(model, param_grid=params, scoring=lambda est, X, y: custom_f1_threshold(est, X, y, threshold), cv=strat_kfold)\u001B[39;00m\n\u001B[1;32m     24\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(model, param_grid\u001B[38;5;241m=\u001B[39mparams, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m est, X, y: custom_f1_threshold(est, X, y, threshold), cv\u001B[38;5;241m=\u001B[39mstrat_kfold)\n\u001B[0;32m---> 25\u001B[0m grid_search\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m     27\u001B[0m best_params \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_params_\n\u001B[1;32m     28\u001B[0m best_score \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_score_\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    966\u001B[0m     )\n\u001B[1;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 970\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_search(evaluate_candidates)\n\u001B[1;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1527\u001B[0m     evaluate_candidates(ParameterGrid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_grid))\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    913\u001B[0m         )\n\u001B[1;32m    914\u001B[0m     )\n\u001B[0;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[1;32m    917\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m    918\u001B[0m         clone(base_estimator),\n\u001B[1;32m    919\u001B[0m         X,\n\u001B[1;32m    920\u001B[0m         y,\n\u001B[1;32m    921\u001B[0m         train\u001B[38;5;241m=\u001B[39mtrain,\n\u001B[1;32m    922\u001B[0m         test\u001B[38;5;241m=\u001B[39mtest,\n\u001B[1;32m    923\u001B[0m         parameters\u001B[38;5;241m=\u001B[39mparameters,\n\u001B[1;32m    924\u001B[0m         split_progress\u001B[38;5;241m=\u001B[39m(split_idx, n_splits),\n\u001B[1;32m    925\u001B[0m         candidate_progress\u001B[38;5;241m=\u001B[39m(cand_idx, n_candidates),\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_and_score_kwargs,\n\u001B[1;32m    927\u001B[0m     )\n\u001B[1;32m    928\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001B[38;5;129;01min\u001B[39;00m product(\n\u001B[1;32m    929\u001B[0m         \u001B[38;5;28menumerate\u001B[39m(candidate_params),\n\u001B[1;32m    930\u001B[0m         \u001B[38;5;28menumerate\u001B[39m(cv\u001B[38;5;241m.\u001B[39msplit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39msplitter\u001B[38;5;241m.\u001B[39msplit)),\n\u001B[1;32m    931\u001B[0m     )\n\u001B[1;32m    932\u001B[0m )\n\u001B[1;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    939\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:895\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    893\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    894\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 895\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    897\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    899\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1294\u001B[0m     n_threads \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1296\u001B[0m fold_coefs_ \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose, prefer\u001B[38;5;241m=\u001B[39mprefer)(\n\u001B[1;32m   1297\u001B[0m     path_func(\n\u001B[1;32m   1298\u001B[0m         X,\n\u001B[1;32m   1299\u001B[0m         y,\n\u001B[1;32m   1300\u001B[0m         pos_class\u001B[38;5;241m=\u001B[39mclass_,\n\u001B[1;32m   1301\u001B[0m         Cs\u001B[38;5;241m=\u001B[39m[C_],\n\u001B[1;32m   1302\u001B[0m         l1_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1_ratio,\n\u001B[1;32m   1303\u001B[0m         fit_intercept\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_intercept,\n\u001B[1;32m   1304\u001B[0m         tol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtol,\n\u001B[1;32m   1305\u001B[0m         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[1;32m   1306\u001B[0m         solver\u001B[38;5;241m=\u001B[39msolver,\n\u001B[1;32m   1307\u001B[0m         multi_class\u001B[38;5;241m=\u001B[39mmulti_class,\n\u001B[1;32m   1308\u001B[0m         max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iter,\n\u001B[1;32m   1309\u001B[0m         class_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_weight,\n\u001B[1;32m   1310\u001B[0m         check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1311\u001B[0m         random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state,\n\u001B[1;32m   1312\u001B[0m         coef\u001B[38;5;241m=\u001B[39mwarm_start_coef_,\n\u001B[1;32m   1313\u001B[0m         penalty\u001B[38;5;241m=\u001B[39mpenalty,\n\u001B[1;32m   1314\u001B[0m         max_squared_sum\u001B[38;5;241m=\u001B[39mmax_squared_sum,\n\u001B[1;32m   1315\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[1;32m   1316\u001B[0m         n_threads\u001B[38;5;241m=\u001B[39mn_threads,\n\u001B[1;32m   1317\u001B[0m     )\n\u001B[1;32m   1318\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m class_, warm_start_coef_ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(classes_, warm_start_coef)\n\u001B[1;32m   1319\u001B[0m )\n\u001B[1;32m   1321\u001B[0m fold_coefs_, _, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mfold_coefs_)\n\u001B[1;32m   1322\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(n_iter_, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint32)[:, \u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:540\u001B[0m, in \u001B[0;36m_logistic_regression_path\u001B[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001B[0m\n\u001B[1;32m    537\u001B[0m         alpha \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m C) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m l1_ratio)\n\u001B[1;32m    538\u001B[0m         beta \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m C) \u001B[38;5;241m*\u001B[39m l1_ratio\n\u001B[0;32m--> 540\u001B[0m     w0, n_iter_i, warm_start_sag \u001B[38;5;241m=\u001B[39m sag_solver(\n\u001B[1;32m    541\u001B[0m         X,\n\u001B[1;32m    542\u001B[0m         target,\n\u001B[1;32m    543\u001B[0m         sample_weight,\n\u001B[1;32m    544\u001B[0m         loss,\n\u001B[1;32m    545\u001B[0m         alpha,\n\u001B[1;32m    546\u001B[0m         beta,\n\u001B[1;32m    547\u001B[0m         max_iter,\n\u001B[1;32m    548\u001B[0m         tol,\n\u001B[1;32m    549\u001B[0m         verbose,\n\u001B[1;32m    550\u001B[0m         random_state,\n\u001B[1;32m    551\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    552\u001B[0m         max_squared_sum,\n\u001B[1;32m    553\u001B[0m         warm_start_sag,\n\u001B[1;32m    554\u001B[0m         is_saga\u001B[38;5;241m=\u001B[39m(solver \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    555\u001B[0m     )\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    558\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    559\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msolver must be one of \u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlbfgs\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    560\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnewton-cg\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msag\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m}, got \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m instead\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m solver\n\u001B[1;32m    561\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:325\u001B[0m, in \u001B[0;36msag_solver\u001B[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001B[0m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mZeroDivisionError\u001B[39;00m(\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrent sag implementation does not handle \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe case step_size * alpha_scaled == 1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[1;32m    324\u001B[0m sag \u001B[38;5;241m=\u001B[39m sag64 \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat64 \u001B[38;5;28;01melse\u001B[39;00m sag32\n\u001B[0;32m--> 325\u001B[0m num_seen, n_iter_ \u001B[38;5;241m=\u001B[39m sag(\n\u001B[1;32m    326\u001B[0m     dataset,\n\u001B[1;32m    327\u001B[0m     coef_init,\n\u001B[1;32m    328\u001B[0m     intercept_init,\n\u001B[1;32m    329\u001B[0m     n_samples,\n\u001B[1;32m    330\u001B[0m     n_features,\n\u001B[1;32m    331\u001B[0m     n_classes,\n\u001B[1;32m    332\u001B[0m     tol,\n\u001B[1;32m    333\u001B[0m     max_iter,\n\u001B[1;32m    334\u001B[0m     loss,\n\u001B[1;32m    335\u001B[0m     step_size,\n\u001B[1;32m    336\u001B[0m     alpha_scaled,\n\u001B[1;32m    337\u001B[0m     beta_scaled,\n\u001B[1;32m    338\u001B[0m     sum_gradient_init,\n\u001B[1;32m    339\u001B[0m     gradient_memory_init,\n\u001B[1;32m    340\u001B[0m     seen_init,\n\u001B[1;32m    341\u001B[0m     num_seen_init,\n\u001B[1;32m    342\u001B[0m     fit_intercept,\n\u001B[1;32m    343\u001B[0m     intercept_sum_gradient,\n\u001B[1;32m    344\u001B[0m     intercept_decay,\n\u001B[1;32m    345\u001B[0m     is_saga,\n\u001B[1;32m    346\u001B[0m     verbose,\n\u001B[1;32m    347\u001B[0m )\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_iter_ \u001B[38;5;241m==\u001B[39m max_iter:\n\u001B[1;32m    350\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    351\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    352\u001B[0m         ConvergenceWarning,\n\u001B[1;32m    353\u001B[0m     )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Performing the GridSearch\n",
    "param_grid = {\n",
    "    'C': [0.005, 0.0095, 0.01, 0.02],\n",
    "    'penalty': ['elasticnet'],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0.45, 0.5, 0.55],\n",
    "    'class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "cls = LogisticRegression(random_state=SEED)\n",
    "threshold = np.linspace(0.595, 0.61, 10)\n",
    "results = find_best_params_for_thresholds(cls, X_train, y_train, param_grid, threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:15:18.264092Z",
     "start_time": "2024-12-07T00:13:57.385702Z"
    }
   },
   "id": "b65426b287f75466"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++ \n",
      " Best Score is 0.4565738234821777\n",
      "Threshold is 0.61\n",
      "{'threshold': 0.61, 'best_params': {'C': 0.005, 'class_weight': 'balanced', 'l1_ratio': 0.5, 'penalty': 'elasticnet', 'solver': 'saga'}, 'best_score': 0.4565738234821777}\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best combinaison\n",
    "best_f1_score = 0\n",
    "best_index = 0\n",
    "for i in range(len(results)):\n",
    "    best = results[i]['best_score']\n",
    "    if best > best_f1_score:\n",
    "        best_f1_score = best\n",
    "        best_index = i\n",
    "\n",
    "best_results = results[best_index]\n",
    "print(\"\\n\\n ++++++++++++++++++++++++++++++++++++++++ \\n Best Score is\", best_f1_score)\n",
    "print(\"Threshold is\", best_results['threshold'])\n",
    "print(best_results)\n",
    "\n",
    "threshold = best_results['threshold']\n",
    "best_params = best_results['best_params']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:15:23.623346Z",
     "start_time": "2024-12-07T00:15:23.612754Z"
    }
   },
   "id": "f5d189225d39e574"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Training the model with the best hyperparameters\n",
    "model = LogisticRegression(**best_params, random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities with the custom threshold\n",
    "y_train_probs = model.predict_proba(X_train)[:, 1]\n",
    "y_train_pred = (y_train_probs >= threshold).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:15:54.443969Z",
     "start_time": "2024-12-07T00:15:51.552158Z"
    }
   },
   "id": "9e07fbf28a0861ae"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score on training set for threshold 0.61: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87    174595\n",
      "           1       0.36      0.63      0.46     28349\n",
      "\n",
      "    accuracy                           0.79    202944\n",
      "   macro avg       0.64      0.72      0.66    202944\n",
      "weighted avg       0.85      0.79      0.81    202944\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on training set\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "report = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "\n",
    "print(f\"F1-Score on training set for threshold {threshold:.2f}: {f1:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:15:57.731856Z",
     "start_time": "2024-12-07T00:15:56.635832Z"
    }
   },
   "id": "7e8ca71d7eef452f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Predicting probabilities on the test set\n",
    "y_test_probs = model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_probs >= threshold).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:16:25.428415Z",
     "start_time": "2024-12-07T00:16:25.410715Z"
    }
   },
   "id": "1be906d881eec03d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'test_predictionsLogReg2.csv'\n"
     ]
    }
   ],
   "source": [
    "# Saving predictions in a .csv file for the Kaggle submission\n",
    "\n",
    "y_test_pred = pd.DataFrame(y_test_pred, columns=['Diabetes_binary'], index=test_data['Unnamed: 0'])\n",
    "y_test_pred.index.name = 'index'\n",
    "y_test_pred.to_csv(\"test_predictionsLogReg2.csv\", index=True)\n",
    "\n",
    "print(f\"Predictions saved to 'test_predictionsLogReg2.csv'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T00:16:29.278486Z",
     "start_time": "2024-12-07T00:16:29.227528Z"
    }
   },
   "id": "f66e990030fb1f2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
